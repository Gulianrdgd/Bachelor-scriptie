{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQyNbClt5lBj",
        "outputId": "ef9e4e5c-453f-4464-e772-d9043b512a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 65.3 kB of archives.\n",
            "After this operation, 223 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Fetched 65.3 kB in 1s (60.4 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 129824 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "--2023-07-22 12:59:17--  https://github.com/Gulianrdgd/tflite-support/releases/download/3.10.0/tflite_support-3.10.0-cp310-cp310-linux_x86_64.whl\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/644401982/16d93feb-7e57-4009-bf81-25826ab0aada?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230722%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230722T125917Z&X-Amz-Expires=300&X-Amz-Signature=5dbc137f78c37daeb944e82c0a985dfaff6630ca4fe0a38f6b4840036fa707c7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=644401982&response-content-disposition=attachment%3B%20filename%3Dtflite_support-3.10.0-cp310-cp310-linux_x86_64.whl&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-07-22 12:59:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/644401982/16d93feb-7e57-4009-bf81-25826ab0aada?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230722%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230722T125917Z&X-Amz-Expires=300&X-Amz-Signature=5dbc137f78c37daeb944e82c0a985dfaff6630ca4fe0a38f6b4840036fa707c7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=644401982&response-content-disposition=attachment%3B%20filename%3Dtflite_support-3.10.0-cp310-cp310-linux_x86_64.whl&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42909404 (41M) [application/octet-stream]\n",
            "Saving to: ‘tflite_support-3.10.0-cp310-cp310-linux_x86_64.whl’\n",
            "\n",
            "tflite_support-3.10 100%[===================>]  40.92M  24.8MB/s    in 1.7s    \n",
            "\n",
            "2023-07-22 12:59:19 (24.8 MB/s) - ‘tflite_support-3.10.0-cp310-cp310-linux_x86_64.whl’ saved [42909404/42909404]\n",
            "\n",
            "Processing ./tflite_support-3.10.0-cp310-cp310-linux_x86_64.whl\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support==3.10.0) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support==3.10.0) (1.22.4)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support==3.10.0) (23.5.26)\n",
            "Requirement already satisfied: protobuf<4,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support==3.10.0) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from tflite-support==3.10.0)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Collecting pybind11>=2.6.0 (from tflite-support==3.10.0)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite-support==3.10.0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support==3.10.0) (2.21)\n",
            "Installing collected packages: pybind11, sounddevice, tflite-support\n",
            "Successfully installed pybind11-2.11.1 sounddevice-0.4.6 tflite-support-3.10.0\n",
            "Collecting tflite-model-maker==0.4.2\n",
            "  Downloading tflite_model_maker-0.4.2-py3-none-any.whl (577 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.3/577.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras==2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-models-official==2.3.0 (from tflite-model-maker==0.4.2)\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.2) (1.22.4)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.2) (8.4.0)\n",
            "Collecting sentencepiece>=0.1.91 (from tflite-model-maker==0.4.2)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.2) (4.9.2)\n",
            "Collecting fire>=0.3.1 (from tflite-model-maker==0.4.2)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.2) (23.5.26)\n",
            "Requirement already satisfied: absl-py>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.2) (1.4.0)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from tflite-model-maker==0.4.2)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tflite-support>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.2) (3.10.0)\n",
            "Collecting tensorflowjs<3.19.0,>=2.4.0 (from tflite-model-maker==0.4.2)\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.2) (2.12.0)\n",
            "INFO: pip is looking at multiple versions of tflite-model-maker to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numba==0.53 (from tflite-model-maker) (from versions: 0.1, 0.2, 0.3, 0.5.0, 0.6.0, 0.7.0, 0.7.1, 0.7.2, 0.8.0, 0.8.1, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.12.2, 0.13.0, 0.13.2, 0.13.3, 0.13.4, 0.14.0, 0.15.1, 0.16.0, 0.17.0, 0.18.1, 0.18.2, 0.19.1, 0.19.2, 0.20.0, 0.21.0, 0.22.0, 0.22.1, 0.23.0, 0.23.1, 0.24.0, 0.25.0, 0.26.0, 0.27.0, 0.28.1, 0.29.0, 0.30.0, 0.30.1, 0.31.0, 0.32.0, 0.33.0, 0.34.0, 0.35.0, 0.36.1, 0.36.2, 0.37.0, 0.38.0, 0.38.1, 0.39.0, 0.40.0, 0.40.1, 0.41.0, 0.42.0, 0.42.1, 0.43.0, 0.43.1, 0.44.0, 0.44.1, 0.45.0, 0.45.1, 0.46.0, 0.47.0, 0.48.0, 0.49.0, 0.49.1rc1, 0.49.1, 0.50.0rc1, 0.50.0, 0.50.1, 0.51.0rc1, 0.51.0, 0.51.1, 0.51.2, 0.52.0rc2, 0.55.0rc1, 0.55.0, 0.55.1, 0.55.2, 0.56.0rc1, 0.56.0, 0.56.2, 0.56.3, 0.56.4, 0.57.0rc1, 0.57.0, 0.57.1rc1, 0.57.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for numba==0.53\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting python_speech_features\n",
            "  Using cached python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=0cf9e4af213f547782a0baefef5ce02f447d364fa72329f9a1d13cc31e66bd3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n"
          ]
        }
      ],
      "source": [
        "import keras.models\n",
        "!sudo apt -y install libportaudio2\n",
        "\n",
        "# The code below is needed to run the code in Google Colab, which uses python3.10\n",
        "!wget https://github.com/Gulianrdgd/tflite-support/releases/download/3.10.0/tflite_support-3.10.0-cp310-cp310-linux_x86_64.whl\n",
        "!pip install ./tflite_support-3.10.0-cp310-cp310-linux_x86_64.whl\n",
        "\n",
        "!pip install tflite-model-maker==0.4.2 python_speech_features keras==2.11.0\n",
        "!pip install python_speech_features --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.io import wavfile\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Input, Bidirectional, BatchNormalization, Lambda, Dot, Softmax, LSTM\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import backend\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sklearn\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from python_speech_features import mfcc\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IWjzos56Qk-",
        "outputId": "6d0fd217-29a7-4c81-94d8-3bdb70894cd7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export the model\n",
        "\n",
        "The last step is exporting your model into the TensorFlow Lite format for execution on mobile/embedded devices and into the [SavedModel format](https://www.tensorflow.org/guide/saved_model) for execution elsewhere.\n",
        "\n",
        "When exporting a `.tflite` file from Model Maker, it includes [model metadata](https://www.tensorflow.org/lite/inference_with_metadata/overview) that describes various details that can later help during inference. It even includes a copy of the classification labels file, so you don't need to a separate `labels.txt` file. (In the next section, we show how to use this metadata to run an inference.)"
      ],
      "metadata": {
        "id": "E2B0Ox3l6aEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TFLITE_ORIG_FILENAME = '/content/drive/MyDrive/model_data_0_lstm_2_2kHz_mid_15_dirty-label.h5'\n",
        "TFLITE_FILENAME = 'browserfft-speech.tflite'\n",
        "TFLITE_METADATA_FILENAME = TFLITE_ORIG_FILENAME.replace('.h5', \".tflite\")\n",
        "SAMPLE_RATE=16000\n",
        "CHANNELS = 1\n",
        "LABEL_FILE = '30.txt'"
      ],
      "metadata": {
        "id": "1RdBR7Dx6S84"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tflite_support.metadata_writers import audio_classifier\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "\n",
        "#model = tf.keras.models.load_model(TFLITE_ORIG_FILENAME)\n",
        "\n",
        "# Only for LSTM\n",
        "\n",
        "learning_rate = 0.0001\n",
        "loss = \"sparse_categorical_crossentropy\"\n",
        "inputs = Input((101, 40, 1), name='input')\n",
        "\n",
        "x = Conv2D(10, (5, 1), activation='relu', padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Lambda(lambda q: backend.squeeze(q, -1), name='squeeze_last_dim')(x)\n",
        "\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]\n",
        "\n",
        "xFirst = Lambda(lambda q: q[:, -1])(x)  # [b_s, vec_dim]\n",
        "query = Dense(128)(xFirst)\n",
        "\n",
        "# dot product attention\n",
        "attScores = Dot(axes=[1, 2])([query, x])\n",
        "attScores = Softmax(name='attSoftmax')(attScores)  # [b_s, seq_len]\n",
        "\n",
        "# rescale sequence\n",
        "attVector = Dot(axes=[1, 1])([attScores, x])  # [b_s, vec_dim]\n",
        "\n",
        "x = Dense(64, activation='relu')(attVector)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32)(x)\n",
        "\n",
        "output = Dense(30, activation='softmax', name='output')(x)\n",
        "model = Model(inputs=[inputs], outputs=[output])\n",
        "\n",
        "# compile model\n",
        "optimiser = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimiser, loss=loss, metrics=[\"accuracy\"])\n",
        "\n",
        "model.load_weights(TFLITE_ORIG_FILENAME)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.experimental_new_converter=True\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "open(TFLITE_FILENAME, \"wb\").write(tflite_model)\n",
        "\n",
        "AudioClassifierWriter = audio_classifier.MetadataWriter\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = AudioClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(f'{TFLITE_FILENAME}'), SAMPLE_RATE, CHANNELS ,\n",
        "    [LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), f'{TFLITE_METADATA_FILENAME}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqBhXjEm6ea2",
        "outputId": "51de928c-be0a-492b-c060-e7985342fd34"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"AudioClassifier\",\n",
            "  \"description\": \"Identify the most prominent type in the audio clip from a known set of categories.\",\n",
            "  \"subgraph_metadata\": [\n",
            "    {\n",
            "      \"input_tensor_metadata\": [\n",
            "        {\n",
            "          \"name\": \"audio_clip\",\n",
            "          \"description\": \"Input audio clip to be classified.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"AudioProperties\",\n",
            "            \"content_properties\": {\n",
            "              \"sample_rate\": 16000,\n",
            "              \"channels\": 1\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          }\n",
            "        }\n",
            "      ],\n",
            "      \"output_tensor_metadata\": [\n",
            "        {\n",
            "          \"name\": \"probability\",\n",
            "          \"description\": \"Scores of the labels respectively.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"FeatureProperties\",\n",
            "            \"content_properties\": {\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "            \"max\": [\n",
            "              1.0\n",
            "            ],\n",
            "            \"min\": [\n",
            "              0.0\n",
            "            ]\n",
            "          },\n",
            "          \"associated_files\": [\n",
            "            {\n",
            "              \"name\": \"30.txt\",\n",
            "              \"description\": \"Labels for categories that the model can recognize.\",\n",
            "              \"type\": \"TENSOR_AXIS_LABELS\"\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tflite_support import metadata\n",
        "import json\n",
        "\n",
        "def get_labels(model):\n",
        "  \"\"\"Returns a list of labels, extracted from the model metadata.\"\"\"\n",
        "  displayer = metadata.MetadataDisplayer.with_model_file(model)\n",
        "  labels_file = displayer.get_packed_associated_file_list()[0]\n",
        "  labels = displayer.get_associated_file_buffer(labels_file).decode()\n",
        "  return [line for line in labels.split('\\n')]\n",
        "\n",
        "def get_input_sample_rate(model):\n",
        "  \"\"\"Returns the model's expected sample rate, from the model metadata.\"\"\"\n",
        "  displayer = metadata.MetadataDisplayer.with_model_file(model)\n",
        "  metadata_json = json.loads(displayer.get_metadata_json())\n",
        "  input_tensor_metadata = metadata_json['subgraph_metadata'][0][\n",
        "          'input_tensor_metadata'][0]\n",
        "  input_content_props = input_tensor_metadata['content']['content_properties']\n",
        "  return input_content_props['sample_rate']\n",
        "\n",
        "  # Ensure the audio sample fits the model input\n",
        "interpreter = tf.lite.Interpreter(TFLITE_METADATA_FILENAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "input_size = input_details[0]['shape'][1]\n",
        "sample_rate = get_input_sample_rate(TFLITE_METADATA_FILENAME)\n",
        "\n",
        "print(input_details)\n",
        "print(output_details)\n",
        "print(input_size)\n",
        "print(sample_rate)\n",
        "\n",
        "\n",
        "mfcc = []\n",
        "for i in range(101):\n",
        "  mfcc.append([])\n",
        "  for j in range(40):\n",
        "    mfcc[i].append(0.0)\n",
        "\n",
        "mfcc = np.array(mfcc, dtype=np.float32)\n",
        "mfcc = mfcc.reshape(1, 101, 40, 1)\n",
        "\n",
        "# Run inference\n",
        "interpreter.allocate_tensors()\n",
        "interpreter.set_tensor(input_details[0]['index'], mfcc)\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)"
      ],
      "metadata": {
        "id": "UoZYpaVR6itV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ea9fef-bbab-4b17-fe96-b761eaeb3d7f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'serving_default_input:0', 'index': 0, 'shape': array([  1, 101,  40,   1], dtype=int32), 'shape_signature': array([ -1, 101,  40,   1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'StatefulPartitionedCall:0', 'index': 109, 'shape': array([ 1, 30], dtype=int32), 'shape_signature': array([-1, 30], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "101\n",
            "16000\n",
            "[[0.0326908  0.02021374 0.02794598 0.02265681 0.02229991 0.04373153\n",
            "  0.03703569 0.02993943 0.02368657 0.02385453 0.07419721 0.01960711\n",
            "  0.01765985 0.01509392 0.02296214 0.04217013 0.03766866 0.0234642\n",
            "  0.02849479 0.03220792 0.03180071 0.05055904 0.04047019 0.02242921\n",
            "  0.04382484 0.04284928 0.02398062 0.08011651 0.03870561 0.02768308]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(TFLITE_METADATA_FILENAME)"
      ],
      "metadata": {
        "id": "YsgQukIT6nmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9fa1d018-b273-4916-e4aa-5fc37fddf0bf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b6d46613-79eb-4528-8587-9fdbc799f5ab\", \"model_data_0_lstm_2_2kHz_mid_15_dirty-label.tflite\", 226925)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}